{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW06: –î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –∏ –∞–Ω—Å–∞–º–±–ª–∏\n",
        "\n",
        "**–¶–µ–ª—å:** –°—Ä–∞–≤–Ω–∏—Ç—å –¥–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –∏ –∞–Ω—Å–∞–º–±–ª–∏ (Random Forest, Boosting) –Ω–∞ –≤—Å–µ—Ö 4 –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –∫—É—Ä—Å–∞.\n",
        "\n",
        "**–î–∞—Ç–∞—Å–µ—Ç—ã:**\n",
        "- `S06-hw-dataset-01.csv` ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —É–º–µ—Ä–µ–Ω–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å\n",
        "- `S06-hw-dataset-02.csv` ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Å–ª–æ–∂–Ω–∞—è (–Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è)\n",
        "- `S06-hw-dataset-03.csv` ‚Äî –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å (3 –∫–ª–∞—Å—Å–∞)\n",
        "- `S06-hw-dataset-04.csv` ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å (fraud-like)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, \n",
        "    GradientBoostingClassifier,\n",
        "    HistGradientBoostingClassifier\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, \n",
        "    roc_auc_score, \n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_curve, \n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏\n",
        "pd.set_option('display.max_columns', None)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä dataset-01:\n",
            "   –†–∞–∑–º–µ—Ä: 12000 —Å—Ç—Ä–æ–∫, 30 —Å—Ç–æ–ª–±—Ü–æ–≤\n",
            "   –ö–ª–∞—Å—Å–æ–≤: 2\n",
            "   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ target: {0: 0.6765833333333333, 1: 0.3234166666666667}\n",
            "\n",
            "üìä dataset-02:\n",
            "   –†–∞–∑–º–µ—Ä: 18000 —Å—Ç—Ä–æ–∫, 39 —Å—Ç–æ–ª–±—Ü–æ–≤\n",
            "   –ö–ª–∞—Å—Å–æ–≤: 2\n",
            "   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ target: {0: 0.7373888888888889, 1: 0.26261111111111113}\n",
            "\n",
            "üìä dataset-03:\n",
            "   –†–∞–∑–º–µ—Ä: 15000 —Å—Ç—Ä–æ–∫, 30 —Å—Ç–æ–ª–±—Ü–æ–≤\n",
            "   –ö–ª–∞—Å—Å–æ–≤: 3\n",
            "   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ target: {0: 0.5425333333333333, 1: 0.30233333333333334, 2: 0.15513333333333335}\n",
            "\n",
            "üìä dataset-04:\n",
            "   –†–∞–∑–º–µ—Ä: 25000 —Å—Ç—Ä–æ–∫, 62 —Å—Ç–æ–ª–±—Ü–æ–≤\n",
            "   –ö–ª–∞—Å—Å–æ–≤: 2\n",
            "   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ target: {0: 0.9508, 1: 0.0492}\n"
          ]
        }
      ],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
        "datasets = {\n",
        "    'dataset-01': pd.read_csv('S06-hw-dataset-01.csv'),\n",
        "    'dataset-02': pd.read_csv('S06-hw-dataset-02.csv'),\n",
        "    'dataset-03': pd.read_csv('S06-hw-dataset-03.csv'),\n",
        "    'dataset-04': pd.read_csv('S06-hw-dataset-04.csv')\n",
        "}\n",
        "\n",
        "# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö\n",
        "for name, df in datasets.items():\n",
        "    n_classes = df['target'].nunique()\n",
        "    class_dist = df['target'].value_counts(normalize=True).to_dict()\n",
        "    print(f\"\\nüìä {name}:\")\n",
        "    print(f\"   –†–∞–∑–º–µ—Ä: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤\")\n",
        "    print(f\"   –ö–ª–∞—Å—Å–æ–≤: {n_classes}\")\n",
        "    print(f\"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ target: {class_dist}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
        "\n",
        "–°–æ–∑–¥–∞–¥–∏–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –Ω–∞ –ª—é–±–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ –§—É–Ω–∫—Ü–∏–∏ –≥–æ—Ç–æ–≤—ã!\n"
          ]
        }
      ],
      "source": [
        "def prepare_data(df):\n",
        "    \"\"\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: –≤—ã–¥–µ–ª–µ–Ω–∏–µ X, y –∏ train/test split.\"\"\"\n",
        "    # –ò—Å–∫–ª—é—á–∞–µ–º id –∏ target\n",
        "    feature_cols = [c for c in df.columns if c not in ['id', 'target']]\n",
        "    X = df[feature_cols].copy()\n",
        "    y = df['target'].copy()\n",
        "    \n",
        "    # Train/test split —Å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test, feature_cols\n",
        "\n",
        "\n",
        "def get_models(is_multiclass=False):\n",
        "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.\"\"\"\n",
        "    models = {\n",
        "        'DummyClassifier': DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE),\n",
        "        \n",
        "        'LogisticRegression': Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('clf', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))\n",
        "        ]),\n",
        "        \n",
        "        'DecisionTree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "        \n",
        "        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),\n",
        "        \n",
        "        'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
        "    }\n",
        "    return models\n",
        "\n",
        "\n",
        "def get_param_grids():\n",
        "    \"\"\"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è GridSearchCV (—É–ø—Ä–æ—â—ë–Ω–Ω—ã–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏).\"\"\"\n",
        "    return {\n",
        "        'DecisionTree': {\n",
        "            'max_depth': [5, 10],\n",
        "            'min_samples_leaf': [5, 20]\n",
        "        },\n",
        "        'RandomForest': {\n",
        "            'max_depth': [10],\n",
        "            'min_samples_leaf': [5],\n",
        "            'n_estimators': [50]\n",
        "        },\n",
        "        'GradientBoosting': {\n",
        "            'max_depth': [3, 5],\n",
        "            'learning_rate': [0.1],\n",
        "            'n_estimators': [50]\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_metrics(y_true, y_pred, y_proba, is_multiclass=False):\n",
        "    \"\"\"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫.\"\"\"\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_true, y_pred)\n",
        "    }\n",
        "    \n",
        "    if is_multiclass:\n",
        "        metrics['f1_macro'] = f1_score(y_true, y_pred, average='macro')\n",
        "        # ROC-AUC –¥–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–∞ (OVR)\n",
        "        try:\n",
        "            metrics['roc_auc_ovr'] = roc_auc_score(y_true, y_proba, multi_class='ovr')\n",
        "        except:\n",
        "            metrics['roc_auc_ovr'] = None\n",
        "    else:\n",
        "        metrics['f1'] = f1_score(y_true, y_pred)\n",
        "        metrics['precision'] = precision_score(y_true, y_pred)\n",
        "        metrics['recall'] = recall_score(y_true, y_pred)\n",
        "        try:\n",
        "            if y_proba.ndim == 2:\n",
        "                metrics['roc_auc'] = roc_auc_score(y_true, y_proba[:, 1])\n",
        "            else:\n",
        "                metrics['roc_auc'] = roc_auc_score(y_true, y_proba)\n",
        "        except:\n",
        "            metrics['roc_auc'] = None\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "\n",
        "def run_experiment(df, dataset_name):\n",
        "    \"\"\"–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –Ω–∞ –æ–¥–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢: {dataset_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–¥–∞—á–∏\n",
        "    n_classes = df['target'].nunique()\n",
        "    is_multiclass = n_classes > 2\n",
        "    print(f\"–¢–∏–ø –∑–∞–¥–∞—á–∏: {'–º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å' if is_multiclass else '–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è'} ({n_classes} –∫–ª–∞—Å—Å–æ–≤)\")\n",
        "    \n",
        "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "    X_train, X_test, y_train, y_test, feature_cols = prepare_data(df)\n",
        "    print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "    \n",
        "    # –ú–æ–¥–µ–ª–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "    models = get_models(is_multiclass)\n",
        "    param_grids = get_param_grids()\n",
        "    results = {}\n",
        "    best_params = {}\n",
        "    trained_models = {}\n",
        "    \n",
        "    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nüîÑ –û–±—É—á–µ–Ω–∏–µ {model_name}...\")\n",
        "        \n",
        "        # GridSearch –¥–ª—è –¥–µ—Ä–µ–≤—å–µ–≤ –∏ –∞–Ω—Å–∞–º–±–ª–µ–π\n",
        "        if model_name in param_grids:\n",
        "            scoring = 'f1_macro' if is_multiclass else 'roc_auc'\n",
        "            grid = GridSearchCV(\n",
        "                model, param_grids[model_name], \n",
        "                cv=5, scoring=scoring, n_jobs=-1\n",
        "            )\n",
        "            grid.fit(X_train, y_train)\n",
        "            best_model = grid.best_estimator_\n",
        "            best_params[model_name] = {\n",
        "                'best_params': grid.best_params_,\n",
        "                'best_cv_score': grid.best_score_\n",
        "            }\n",
        "            print(f\"   Best params: {grid.best_params_}\")\n",
        "            print(f\"   Best CV score: {grid.best_score_:.4f}\")\n",
        "        else:\n",
        "            best_model = model\n",
        "            best_model.fit(X_train, y_train)\n",
        "        \n",
        "        trained_models[model_name] = best_model\n",
        "        \n",
        "        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "        y_pred = best_model.predict(X_test)\n",
        "        try:\n",
        "            y_proba = best_model.predict_proba(X_test)\n",
        "        except:\n",
        "            y_proba = None\n",
        "        \n",
        "        # –ú–µ—Ç—Ä–∏–∫–∏\n",
        "        metrics = compute_metrics(y_test, y_pred, y_proba, is_multiclass)\n",
        "        results[model_name] = metrics\n",
        "        \n",
        "        # –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫\n",
        "        metrics_str = \", \".join([f\"{k}: {v:.4f}\" if v else f\"{k}: N/A\" for k, v in metrics.items()])\n",
        "        print(f\"   –ú–µ—Ç—Ä–∏–∫–∏: {metrics_str}\")\n",
        "    \n",
        "    return {\n",
        "        'results': results,\n",
        "        'best_params': best_params,\n",
        "        'trained_models': trained_models,\n",
        "        'X_test': X_test,\n",
        "        'y_test': y_test,\n",
        "        'feature_cols': feature_cols,\n",
        "        'is_multiclass': is_multiclass\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ –≥–æ—Ç–æ–≤—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (–ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏)\n",
        "\n",
        "–ó–∞–ø—É—Å–∫–∞–π—Ç–µ —è—á–µ–π–∫–∏ –Ω–∏–∂–µ **–ø–æ –æ–¥–Ω–æ–π** ‚Äî –∫–∞–∂–¥–∞—è –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–≤–æ—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ.\n",
        "\n",
        "‚è±Ô∏è **–ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è:** 2-4 –º–∏–Ω—É—Ç—ã –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢: dataset-01\n",
            "======================================================================\n",
            "–¢–∏–ø –∑–∞–¥–∞—á–∏: –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (2 –∫–ª–∞—Å—Å–æ–≤)\n",
            "Train: 9600, Test: 2400\n",
            "\n",
            "üîÑ –û–±—É—á–µ–Ω–∏–µ DummyClassifier...\n",
            "   –ú–µ—Ç—Ä–∏–∫–∏: accuracy: 0.6767, f1: N/A, precision: N/A, recall: N/A, roc_auc: 0.5000\n",
            "\n",
            "üîÑ –û–±—É—á–µ–Ω–∏–µ LogisticRegression...\n",
            "   –ú–µ—Ç—Ä–∏–∫–∏: accuracy: 0.8275, f1: 0.7076, precision: 0.7828, recall: 0.6456, roc_auc: 0.8747\n",
            "\n",
            "üîÑ –û–±—É—á–µ–Ω–∏–µ DecisionTree...\n",
            "   Best params: {'max_depth': 15, 'min_samples_leaf': 20}\n",
            "   Best CV score: 0.9155\n",
            "   –ú–µ—Ç—Ä–∏–∫–∏: accuracy: 0.8650, f1: 0.7868, precision: 0.8038, recall: 0.7706, roc_auc: 0.9122\n",
            "\n",
            "üîÑ –û–±—É—á–µ–Ω–∏–µ RandomForest...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m all_experiments = {}\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, df \u001b[38;5;129;01min\u001b[39;00m datasets.items():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     all_experiments[dataset_name] = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ –í–°–ï –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´ –ó–ê–í–ï–†–®–ï–ù–´!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 116\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(df, dataset_name)\u001b[39m\n\u001b[32m    111\u001b[39m scoring = \u001b[33m'\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_multiclass \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    112\u001b[39m grid = GridSearchCV(\n\u001b[32m    113\u001b[39m     model, param_grids[model_name], \n\u001b[32m    114\u001b[39m     cv=\u001b[32m5\u001b[39m, scoring=scoring, n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m    115\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m best_model = grid.best_estimator_\n\u001b[32m    118\u001b[39m best_params[model_name] = {\n\u001b[32m    119\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_params\u001b[39m\u001b[33m'\u001b[39m: grid.best_params_,\n\u001b[32m    120\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_cv_score\u001b[39m\u001b[33m'\u001b[39m: grid.best_score_\n\u001b[32m    121\u001b[39m }\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igork\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igork\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igork\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igork\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igork\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igork\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igork\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\igork\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "all_experiments = {}\n",
        "print(\"‚úÖ –°–ª–æ–≤–∞—Ä—å all_experiments –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ó–∞–ø—É—Å–∫–∞–π—Ç–µ —è—á–µ–π–∫–∏ –Ω–∏–∂–µ –ø–æ –æ–¥–Ω–æ–π.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Dataset-01 (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —É–º–µ—Ä–µ–Ω–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –Ω–∞ dataset-01\n",
        "all_experiments['dataset-01'] = run_experiment(datasets['dataset-01'], 'dataset-01')\n",
        "print(\"\\n‚úÖ Dataset-01 –∑–∞–≤–µ—Ä—à—ë–Ω!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Dataset-02 (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –Ω–∞ dataset-02\n",
        "all_experiments['dataset-02'] = run_experiment(datasets['dataset-02'], 'dataset-02')\n",
        "print(\"\\n‚úÖ Dataset-02 –∑–∞–≤–µ—Ä—à—ë–Ω!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Dataset-03 (–º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å, 3 –∫–ª–∞—Å—Å–∞)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –Ω–∞ dataset-03\n",
        "all_experiments['dataset-03'] = run_experiment(datasets['dataset-03'], 'dataset-03')\n",
        "print(\"\\n‚úÖ Dataset-03 –∑–∞–≤–µ—Ä—à—ë–Ω!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Dataset-04 (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –Ω–∞ dataset-04\n",
        "all_experiments['dataset-04'] = run_experiment(datasets['dataset-04'], 'dataset-04')\n",
        "print(\"\\n‚úÖ Dataset-04 –∑–∞–≤–µ—Ä—à—ë–Ω!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞: –∫–∞–∫–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –æ–±—É—á–µ–Ω—ã\n",
        "print(\"üìã –°—Ç–∞—Ç—É—Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:\")\n",
        "for ds_name in ['dataset-01', 'dataset-02', 'dataset-03', 'dataset-04']:\n",
        "    status = \"‚úÖ –ì–æ—Ç–æ–≤\" if ds_name in all_experiments else \"‚è≥ –ù–µ –∑–∞–ø—É—â–µ–Ω\"\n",
        "    print(f\"  {ds_name}: {status}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã\n",
        "def create_summary_table(all_experiments):\n",
        "    \"\"\"–°–æ–∑–¥–∞—ë—Ç —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –ø–æ –≤—Å–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º.\"\"\"\n",
        "    rows = []\n",
        "    for dataset_name, exp in all_experiments.items():\n",
        "        is_mc = exp['is_multiclass']\n",
        "        for model_name, metrics in exp['results'].items():\n",
        "            row = {\n",
        "                'Dataset': dataset_name,\n",
        "                'Model': model_name,\n",
        "                'Accuracy': metrics.get('accuracy'),\n",
        "            }\n",
        "            if is_mc:\n",
        "                row['F1'] = metrics.get('f1_macro')\n",
        "                row['ROC-AUC'] = metrics.get('roc_auc_ovr')\n",
        "            else:\n",
        "                row['F1'] = metrics.get('f1')\n",
        "                row['ROC-AUC'] = metrics.get('roc_auc')\n",
        "            rows.append(row)\n",
        "    \n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "summary_df = create_summary_table(all_experiments)\n",
        "print(\"üìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# –í—ã–≤–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É\n",
        "for dataset_name in datasets.keys():\n",
        "    print(f\"\\n{dataset_name}:\")\n",
        "    ds_df = summary_df[summary_df['Dataset'] == dataset_name][['Model', 'Accuracy', 'F1', 'ROC-AUC']]\n",
        "    print(ds_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "def find_best_model(exp):\n",
        "    \"\"\"–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ ROC-AUC –∏–ª–∏ F1.\"\"\"\n",
        "    results = exp['results']\n",
        "    is_mc = exp['is_multiclass']\n",
        "    \n",
        "    best_model = None\n",
        "    best_score = -1\n",
        "    metric_key = 'roc_auc_ovr' if is_mc else 'roc_auc'\n",
        "    \n",
        "    for model_name, metrics in results.items():\n",
        "        score = metrics.get(metric_key) or metrics.get('f1_macro') or metrics.get('f1') or 0\n",
        "        if score and score > best_score:\n",
        "            best_score = score\n",
        "            best_model = model_name\n",
        "    \n",
        "    return best_model, best_score\n",
        "\n",
        "print(\"üèÜ –õ–£–ß–®–ò–ï –ú–û–î–ï–õ–ò –ü–û –î–ê–¢–ê–°–ï–¢–ê–ú:\")\n",
        "print(\"=\"*70)\n",
        "best_models_info = {}\n",
        "\n",
        "for dataset_name, exp in all_experiments.items():\n",
        "    best_model, best_score = find_best_model(exp)\n",
        "    best_models_info[dataset_name] = {\n",
        "        'best_model': best_model,\n",
        "        'best_score': best_score,\n",
        "        'is_multiclass': exp['is_multiclass']\n",
        "    }\n",
        "    metric_name = 'ROC-AUC (OVR)' if exp['is_multiclass'] else 'ROC-AUC'\n",
        "    print(f\"  {dataset_name}: {best_model} ({metric_name} = {best_score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ROC-–∫—Ä–∏–≤—ã–µ –∏ Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ROC-–∫—Ä–∏–≤—ã–µ –¥–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (dataset_name, exp) in enumerate(all_experiments.items()):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    if exp['is_multiclass']:\n",
        "        ax.text(0.5, 0.5, f'{dataset_name}\\n(–ú—É–ª—å—Ç–∏–∫–ª–∞—Å—Å - ROC –Ω–µ –ø—Ä–∏–º–µ–Ω–∏–º–∞)', \n",
        "                ha='center', va='center', fontsize=12, transform=ax.transAxes)\n",
        "        ax.set_xlim([0, 1])\n",
        "        ax.set_ylim([0, 1])\n",
        "    else:\n",
        "        X_test = exp['X_test']\n",
        "        y_test = exp['y_test']\n",
        "        \n",
        "        for model_name in ['LogisticRegression', 'DecisionTree', 'RandomForest', 'GradientBoosting']:\n",
        "            model = exp['trained_models'][model_name]\n",
        "            try:\n",
        "                y_proba = model.predict_proba(X_test)[:, 1]\n",
        "                fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "                auc = exp['results'][model_name].get('roc_auc', 0)\n",
        "                ax.plot(fpr, tpr, label=f'{model_name} (AUC={auc:.3f})', linewidth=2)\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
        "        ax.set_xlabel('False Positive Rate')\n",
        "        ax.set_ylabel('True Positive Rate')\n",
        "        ax.legend(loc='lower right', fontsize=8)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    ax.set_title(f'{dataset_name}', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('artifacts/figures/roc_curves_all.png', dpi=150, bbox_inches='tight')\n",
        "print(\"‚úÖ ROC-–∫—Ä–∏–≤—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ artifacts/figures/roc_curves_all.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix –¥–ª—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (dataset_name, exp) in enumerate(all_experiments.items()):\n",
        "    ax = axes[idx]\n",
        "    best_model_name = best_models_info[dataset_name]['best_model']\n",
        "    best_model = exp['trained_models'][best_model_name]\n",
        "    \n",
        "    y_pred = best_model.predict(exp['X_test'])\n",
        "    cm = confusion_matrix(exp['y_test'], y_pred)\n",
        "    \n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
        "    ax.set_title(f'{dataset_name}\\n(Best: {best_model_name})', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('artifacts/figures/confusion_matrices_all.png', dpi=150, bbox_inches='tight')\n",
        "print(\"‚úÖ Confusion matrices —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ artifacts/figures/confusion_matrices_all.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Permutation Importance –¥–ª—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Permutation Importance –¥–ª—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "all_importances = {}\n",
        "\n",
        "for idx, (dataset_name, exp) in enumerate(all_experiments.items()):\n",
        "    ax = axes[idx]\n",
        "    best_model_name = best_models_info[dataset_name]['best_model']\n",
        "    best_model = exp['trained_models'][best_model_name]\n",
        "    \n",
        "    print(f\"\\nüìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ Permutation Importance –¥–ª—è {dataset_name} ({best_model_name})...\")\n",
        "    \n",
        "    # –í—ã—á–∏—Å–ª—è–µ–º permutation importance\n",
        "    scoring = 'f1_macro' if exp['is_multiclass'] else 'roc_auc'\n",
        "    perm_imp = permutation_importance(\n",
        "        best_model, exp['X_test'], exp['y_test'], \n",
        "        n_repeats=10, random_state=RANDOM_STATE, scoring=scoring, n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä—ë–º —Ç–æ–ø-15\n",
        "    imp_df = pd.DataFrame({\n",
        "        'feature': exp['feature_cols'],\n",
        "        'importance': perm_imp.importances_mean,\n",
        "        'std': perm_imp.importances_std\n",
        "    }).sort_values('importance', ascending=False).head(15)\n",
        "    \n",
        "    all_importances[dataset_name] = imp_df\n",
        "    \n",
        "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "    colors = ['#3498db' if x > 0 else '#e74c3c' for x in imp_df['importance']]\n",
        "    ax.barh(imp_df['feature'], imp_df['importance'], xerr=imp_df['std'], color=colors, alpha=0.8)\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xlabel('Permutation Importance')\n",
        "    ax.set_title(f'{dataset_name} - {best_model_name}', fontsize=11)\n",
        "    ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('artifacts/figures/permutation_importance_all.png', dpi=150, bbox_inches='tight')\n",
        "print(\"\\n‚úÖ Permutation Importance —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ artifacts/figures/permutation_importance_all.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í—ã–≤–æ–¥ —Ç–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "print(\"üìã –¢–û–ü-10 –í–ê–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í –ü–û –î–ê–¢–ê–°–ï–¢–ê–ú:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for dataset_name, imp_df in all_importances.items():\n",
        "    print(f\"\\n{dataset_name}:\")\n",
        "    print(imp_df.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. –ê–Ω–∞–ª–∏–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ (—Ä–∞–∑–Ω—ã–µ random_state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ê–Ω–∞–ª–∏–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –Ω–∞ dataset-01 –∏ dataset-04\n",
        "random_states = [42, 123, 456, 789, 1024]\n",
        "\n",
        "def run_stability_test(df, model_class, param_grid, random_states):\n",
        "    \"\"\"–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö random_state.\"\"\"\n",
        "    scores = []\n",
        "    \n",
        "    feature_cols = [c for c in df.columns if c not in ['id', 'target']]\n",
        "    X = df[feature_cols]\n",
        "    y = df['target']\n",
        "    is_mc = y.nunique() > 2\n",
        "    \n",
        "    for rs in random_states:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=rs, stratify=y\n",
        "        )\n",
        "        \n",
        "        model = model_class(random_state=rs, **param_grid)\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        y_proba = model.predict_proba(X_test)\n",
        "        if is_mc:\n",
        "            score = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
        "        else:\n",
        "            score = roc_auc_score(y_test, y_proba[:, 1])\n",
        "        scores.append(score)\n",
        "    \n",
        "    return np.array(scores)\n",
        "\n",
        "print(\"üîÑ –ê–ù–ê–õ–ò–ó –£–°–¢–û–ô–ß–ò–í–û–°–¢–ò (5 random_state):\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "stability_results = {}\n",
        "\n",
        "# –¢–µ—Å—Ç –¥–ª—è dataset-01 —Å RandomForest\n",
        "print(\"\\nDataset-01 (RandomForest):\")\n",
        "scores_01 = run_stability_test(\n",
        "    datasets['dataset-01'], \n",
        "    RandomForestClassifier, \n",
        "    {'n_estimators': 100, 'max_depth': 10, 'n_jobs': -1},\n",
        "    random_states\n",
        ")\n",
        "stability_results['dataset-01'] = scores_01\n",
        "print(f\"  ROC-AUC –ø–æ –ø—Ä–æ–≥–æ–Ω–∞–º: {scores_01}\")\n",
        "print(f\"  –°—Ä–µ–¥–Ω–µ–µ: {scores_01.mean():.4f} ¬± {scores_01.std():.4f}\")\n",
        "\n",
        "# –¢–µ—Å—Ç –¥–ª—è dataset-04 —Å GradientBoosting\n",
        "print(\"\\nDataset-04 (GradientBoosting):\")\n",
        "scores_04 = run_stability_test(\n",
        "    datasets['dataset-04'], \n",
        "    GradientBoostingClassifier, \n",
        "    {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1},\n",
        "    random_states\n",
        ")\n",
        "stability_results['dataset-04'] = scores_04\n",
        "print(f\"  ROC-AUC –ø–æ –ø—Ä–æ–≥–æ–Ω–∞–º: {scores_04}\")\n",
        "print(f\"  –°—Ä–µ–¥–Ω–µ–µ: {scores_04.mean():.4f} ¬± {scores_04.std():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –Ω–∞ test\n",
        "metrics_test = {}\n",
        "for dataset_name, exp in all_experiments.items():\n",
        "    metrics_test[dataset_name] = {}\n",
        "    for model_name, metrics in exp['results'].items():\n",
        "        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy types –≤ python types –¥–ª—è JSON\n",
        "        metrics_test[dataset_name][model_name] = {\n",
        "            k: float(v) if v is not None else None \n",
        "            for k, v in metrics.items()\n",
        "        }\n",
        "\n",
        "with open('artifacts/metrics_test.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(metrics_test, f, indent=2, ensure_ascii=False)\n",
        "print(\"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ artifacts/metrics_test.json\")\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "search_summaries = {}\n",
        "for dataset_name, exp in all_experiments.items():\n",
        "    search_summaries[dataset_name] = {}\n",
        "    for model_name, params in exp['best_params'].items():\n",
        "        search_summaries[dataset_name][model_name] = {\n",
        "            'best_params': {k: str(v) for k, v in params['best_params'].items()},\n",
        "            'best_cv_score': float(params['best_cv_score'])\n",
        "        }\n",
        "\n",
        "with open('artifacts/search_summaries.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(search_summaries, f, indent=2, ensure_ascii=False)\n",
        "print(\"‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ artifacts/search_summaries.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (–≤—ã–±–∏—Ä–∞–µ–º dataset-04 –∫–∞–∫ –Ω–∞–∏–±–æ–ª–µ–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π)\n",
        "# –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π –¥–∞—Ç–∞—Å–µ—Ç\n",
        "selected_dataset = 'dataset-04'\n",
        "best_model_name = best_models_info[selected_dataset]['best_model']\n",
        "best_model = all_experiments[selected_dataset]['trained_models'][best_model_name]\n",
        "\n",
        "joblib.dump(best_model, 'artifacts/best_model.joblib')\n",
        "print(f\"‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å ({best_model_name} –¥–ª—è {selected_dataset}) —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ artifacts/best_model.joblib\")\n",
        "\n",
        "# –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
        "best_model_meta = {\n",
        "    'dataset': selected_dataset,\n",
        "    'model_name': best_model_name,\n",
        "    'best_params': search_summaries.get(selected_dataset, {}).get(best_model_name, {}).get('best_params', {}),\n",
        "    'metrics_on_test': metrics_test[selected_dataset][best_model_name]\n",
        "}\n",
        "\n",
        "with open('artifacts/best_model_meta.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(best_model_meta, f, indent=2, ensure_ascii=False)\n",
        "print(\"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ artifacts/best_model_meta.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
        "import os\n",
        "\n",
        "print(\"üìÅ –°–û–î–ï–†–ñ–ò–ú–û–ï –ü–ê–ü–ö–ò artifacts/:\")\n",
        "for root, dirs, files in os.walk('artifacts'):\n",
        "    level = root.replace('artifacts', '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files:\n",
        "        filepath = os.path.join(root, file)\n",
        "        size = os.path.getsize(filepath)\n",
        "        print(f'{subindent}{file} ({size} bytes)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. –í—ã–≤–æ–¥—ã\n",
        "\n",
        "### –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
        "\n",
        "**Dataset-01 (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —É–º–µ—Ä–µ–Ω–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å):**\n",
        "- –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã (RandomForest, GradientBoosting) –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç –ø—Ä–æ—Å—Ç—ã–µ baseline'—ã\n",
        "- –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–ª–∞–≥–æ–¥–∞—Ä—è –ª–∏–Ω–µ–π–Ω–æ–π —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö\n",
        "- –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Å–∫–ª–æ–Ω–Ω–æ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é\n",
        "\n",
        "**Dataset-02 (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è):**\n",
        "- –ù–∞ —ç—Ç–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –æ—Å–æ–±–µ–Ω–Ω–æ –∑–∞–º–µ—Ç–Ω–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –∞–Ω—Å–∞–º–±–ª–µ–π –Ω–∞–¥ –ª–∏–Ω–µ–π–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏\n",
        "- GradientBoosting —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
        "- –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "\n",
        "**Dataset-03 (–º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å, 3 –∫–ª–∞—Å—Å–∞):**\n",
        "- –î–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ F1-macro –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é –º–µ—Ç—Ä–∏–∫—É\n",
        "- ROC-AUC (OVR) —Ç–∞–∫–∂–µ –ø—Ä–∏–º–µ–Ω–∏–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
        "- –ê–Ω—Å–∞–º–±–ª–∏ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –ª—É—á—à–µ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤\n",
        "\n",
        "**Dataset-04 (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å):**\n",
        "- Accuracy ‚Äî –æ–±–º–∞–Ω—á–∏–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ (–º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –≤—ã—Å–æ–∫—É—é accuracy –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—è –º–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω—ã–π –∫–ª–∞—Å—Å)\n",
        "- ROC-AUC –∏ F1 –¥–∞—é—Ç –±–æ–ª–µ–µ —á–µ—Å—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞\n",
        "- –ê–Ω—Å–∞–º–±–ª–∏ –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å —Ä–µ–¥–∫–∏–º –∫–ª–∞—Å—Å–æ–º\n",
        "\n",
        "### –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã –æ –¥–µ—Ä–µ–≤—å—è—Ö –∏ –∞–Ω—Å–∞–º–±–ª—è—Ö\n",
        "\n",
        "1. **–û–¥–∏–Ω–æ—á–Ω–æ–µ –¥–µ—Ä–µ–≤–æ –ª–µ–≥–∫–æ –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è** ‚Äî –∫–æ–Ω—Ç—Ä–æ–ª—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (max_depth, min_samples_leaf, ccp_alpha) –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω\n",
        "\n",
        "2. **Bagging (Random Forest)** —É–º–µ–Ω—å—à–∞–µ—Ç variance –∑–∞ —Å—á—ë—Ç —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–µ—Ä–µ–≤—å–µ–≤ + —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
        "\n",
        "3. **Boosting** –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∞–µ—Ç –º–æ–¥–µ–ª—å, —Ñ–æ–∫—É—Å–∏—Ä—É—è—Å—å –Ω–∞ –æ—à–∏–±–∫–∞—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π ‚Äî —á–∞—Å—Ç–æ –¥–∞—ë—Ç –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ –º–æ–∂–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å—Å—è –ø—Ä–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–º —á–∏—Å–ª–µ –∏—Ç–µ—Ä–∞—Ü–∏–π\n",
        "\n",
        "4. **–ß–µ—Å—Ç–Ω—ã–π ML-–ø—Ä–æ—Ç–æ–∫–æ–ª:** —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π random_state, —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ, CV —Ç–æ–ª—å–∫–æ –Ω–∞ train, —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ test ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
        "\n",
        "5. **–í—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–¥–∞—á–∏:** –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ –∫–ª–∞—Å—Å–æ–≤ accuracy –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –Ω—É–∂–Ω—ã ROC-AUC, F1, Precision/Recall\n",
        "\n",
        "6. **Permutation Importance** –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–∂–µ —Å–ª–æ–∂–Ω—ã–µ –∞–Ω—Å–∞–º–±–ª–∏ –∏ –ø–æ–Ω—è—Ç—å, –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–∞–ª—å–Ω–æ –≤–ª–∏—è—é—Ç –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"‚úÖ –î–û–ú–ê–®–ù–ï–ï –ó–ê–î–ê–ù–ò–ï HW06 –í–´–ü–û–õ–ù–ï–ù–û!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n–ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã:\")\n",
        "print(\"  - artifacts/metrics_test.json\")\n",
        "print(\"  - artifacts/search_summaries.json\")\n",
        "print(\"  - artifacts/best_model.joblib\")\n",
        "print(\"  - artifacts/best_model_meta.json\")\n",
        "print(\"  - artifacts/figures/roc_curves_all.png\")\n",
        "print(\"  - artifacts/figures/confusion_matrices_all.png\")\n",
        "print(\"  - artifacts/figures/permutation_importance_all.png\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
